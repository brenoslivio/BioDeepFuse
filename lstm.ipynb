{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: feat_extraction/train - Acesso negado.\n",
      "Creating Directory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Meu Drive\\Doutorado\\UFZ\\RNA Biology\\DL_RNAFeatExtraction\\seqdata.py:161: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframes = pd.concat([pd.read_csv(f) for f in datasets], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: feat_extraction/test - Acesso negado.\n",
      "Creating Directory...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import (Concatenate, Conv1D, Dense, Dropout, Flatten,\n",
    "                                    Input, LSTM, MaxPooling1D, TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "import seqdata\n",
    "from transformers import AutoTokenizer, BertTokenizer, TFAutoModel\n",
    "\n",
    "\n",
    "train = seqdata.Seq('train/')\n",
    "test = seqdata.Seq('test/')\n",
    "\n",
    "max_len = seqdata.pad_data(train, test)\n",
    "max_len\n",
    "\n",
    "train.feature_extraction([1, 2, 3, 4, 5, 6, 7, 8], True)\n",
    "test.feature_extraction([1, 2, 3, 4, 5, 6, 7, 8], False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM + feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 3339, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 3337, 64)     832         ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 3335, 64)     12352       ['conv1d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 3335, 64)     0           ['conv1d_7[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 1667, 64)    0           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 1667, 64)    0           ['max_pooling1d_3[0][0]']        \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 426)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 128)          98816       ['time_distributed_3[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 426)          0           ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 554)          0           ['lstm_5[0][0]',                 \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 128)          71040       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 8)            1032        ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 184,072\n",
      "Trainable params: 184,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/10\n",
      "37/37 [==============================] - 163s 4s/step - loss: 0.9362 - Precision: 0.8570\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 168s 5s/step - loss: 0.4452 - Precision: 0.9078\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 162s 4s/step - loss: 0.3471 - Precision: 0.9247\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 165s 4s/step - loss: 0.2916 - Precision: 0.9350\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 164s 4s/step - loss: 0.2446 - Precision: 0.9458\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 160s 4s/step - loss: 0.2249 - Precision: 0.9462\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 159s 4s/step - loss: 0.1881 - Precision: 0.9559\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 162s 4s/step - loss: 0.1668 - Precision: 0.9681\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 164s 4s/step - loss: 0.1539 - Precision: 0.9657\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 169s 5s/step - loss: 0.1352 - Precision: 0.9736\n",
      "21/21 [==============================] - 11s 489ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miRNA</th>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mRNA</th>\n",
       "      <td>0.994350</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_miRNA</th>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.691589</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rRNA</th>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.978261</td>\n",
       "      <td>0.971223</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snoRNA</th>\n",
       "      <td>0.509434</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snRNA</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmRNA</th>\n",
       "      <td>0.985294</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tRNA</th>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.872274</td>\n",
       "      <td>0.872274</td>\n",
       "      <td>0.872274</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.770552</td>\n",
       "      <td>0.780902</td>\n",
       "      <td>0.768722</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.876380</td>\n",
       "      <td>0.872274</td>\n",
       "      <td>0.870384</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.872274</td>\n",
       "      <td>0.872274</td>\n",
       "      <td>0.872274</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "miRNA          0.575758  0.365385  0.447059     52.0\n",
       "mRNA           0.994350  0.946237  0.969697    186.0\n",
       "pre_miRNA      0.649123  0.740000  0.691589     50.0\n",
       "rRNA           0.964286  0.978261  0.971223    138.0\n",
       "snoRNA         0.509434  0.771429  0.613636     35.0\n",
       "snRNA          0.550000  0.500000  0.523810     22.0\n",
       "tmRNA          0.985294  0.957143  0.971014     70.0\n",
       "tRNA           0.936170  0.988764  0.961749     89.0\n",
       "micro avg      0.872274  0.872274  0.872274    642.0\n",
       "macro avg      0.770552  0.780902  0.768722    642.0\n",
       "weighted avg   0.876380  0.872274  0.870384    642.0\n",
       "samples avg    0.872274  0.872274  0.872274    642.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functional Model Keras\n",
    "\n",
    "# CNN input\n",
    "cnn_input = Input(shape=(max_len, 4))\n",
    "\n",
    "# CNN layers\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(cnn_input)\n",
    "conv2 = Conv1D(filters=64, kernel_size=3, activation='relu')(conv1)\n",
    "dropout1 = Dropout(0.5)(conv2)\n",
    "max_pool1 = MaxPooling1D(pool_size=2)(dropout1)\n",
    "cnn_output = TimeDistributed(Flatten())(max_pool1)\n",
    "\n",
    "# LSTM layer\n",
    "lstm_output = LSTM(128)(cnn_output)\n",
    "\n",
    "# Feature extraction input\n",
    "feature_input = Input(shape=(426,))\n",
    "feature_output = Flatten()(feature_input)\n",
    "\n",
    "# Concatenate LSTM and feature extraction outputs\n",
    "concat_output = Concatenate()([lstm_output, feature_output])\n",
    "\n",
    "# Dense layer\n",
    "dense_layer = Dense(128, activation='relu')(concat_output)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(8, activation='softmax')(dense_layer)\n",
    "\n",
    "# Model definition\n",
    "model = Model(inputs=[cnn_input, feature_input], outputs=output_layer)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.Precision(name=\"Precision\")])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Plot model\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False\n",
    ")\n",
    "\n",
    "# Model training\n",
    "model.fit([train.seqs, train.features], train.labels, batch_size=64, epochs=10)\n",
    "\n",
    "# Model prediction\n",
    "model_predictions = model.predict([test.seqs, test.features])\n",
    "\n",
    "# Convert predictions to one-hot encoded format\n",
    "y_pred = []\n",
    "for row in model_predictions:\n",
    "    pred = [0 for _ in range(8)]\n",
    "    pred[np.argmax(row)] = 1\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(test.labels, y_pred, target_names=test.names, output_dict=True)\n",
    "pd.DataFrame(report).T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Only LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 3339, 4)]         0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 3337, 128)         1664      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 3335, 128)         49280     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3335, 128)         0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 1667, 128)        0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 1667, 128)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 1667, 256)        263168    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742,280\n",
      "Trainable params: 742,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 950s 14s/step - loss: 1.9172 - Precision: 0.4091 - val_loss: 2.6255 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 927s 14s/step - loss: 1.5543 - Precision: 0.5707 - val_loss: 2.6380 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 864s 13s/step - loss: 1.3865 - Precision: 0.6588 - val_loss: 2.1735 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 797s 12s/step - loss: 1.2396 - Precision: 0.7367 - val_loss: 2.0036 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 840s 13s/step - loss: 1.0917 - Precision: 0.7054 - val_loss: 2.6953 - val_Precision: 0.1720 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 819s 12s/step - loss: 1.2291 - Precision: 0.7309 - val_loss: 1.8134 - val_Precision: 0.8750 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 876s 13s/step - loss: 0.8681 - Precision: 0.7841 - val_loss: 0.7851 - val_Precision: 0.9682 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 929s 14s/step - loss: 0.8369 - Precision: 0.7715 - val_loss: 0.6506 - val_Precision: 0.9560 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 957s 14s/step - loss: 0.7158 - Precision: 0.8224 - val_loss: 0.8561 - val_Precision: 0.9576 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 1028s 16s/step - loss: 0.6958 - Precision: 0.8122 - val_loss: 0.4678 - val_Precision: 0.9757 - lr: 0.0010\n",
      "21/21 [==============================] - 69s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miRNA</th>\n",
       "      <td>0.408163</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mRNA</th>\n",
       "      <td>0.924855</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_miRNA</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rRNA</th>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>138.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snoRNA</th>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snRNA</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmRNA</th>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tRNA</th>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.910112</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.788162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729239</td>\n",
       "      <td>0.651000</td>\n",
       "      <td>0.658856</td>\n",
       "      <td>642.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.807598</td>\n",
       "      <td>0.788162</td>\n",
       "      <td>0.782082</td>\n",
       "      <td>642.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "miRNA          0.408163  0.769231  0.533333   52.000000\n",
       "mRNA           0.924855  0.860215  0.891365  186.000000\n",
       "pre_miRNA      0.750000  0.480000  0.585366   50.000000\n",
       "rRNA           0.791667  0.963768  0.869281  138.000000\n",
       "snoRNA         0.529412  0.257143  0.346154   35.000000\n",
       "snRNA          0.571429  0.181818  0.275862   22.000000\n",
       "tmRNA          0.948276  0.785714  0.859375   70.000000\n",
       "tRNA           0.910112  0.910112  0.910112   89.000000\n",
       "accuracy       0.788162  0.788162  0.788162    0.788162\n",
       "macro avg      0.729239  0.651000  0.658856  642.000000\n",
       "weighted avg   0.807598  0.788162  0.782082  642.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Dropout, Flatten, Input, Bidirectional, LSTM, MaxPooling1D, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import seqdata\n",
    "\n",
    "train_data = seqdata.Seq('train/')\n",
    "test_data = seqdata.Seq('test/')\n",
    "\n",
    "seqdata.pad_data(train_data, test_data)\n",
    "\n",
    "# CNN layers\n",
    "input_layer = Input(shape=(train_data.seqs.shape[1], 4))\n",
    "conv1 = Conv1D(128, 3, activation='relu')(input_layer)\n",
    "conv2 = Conv1D(128, 3, activation='relu')(conv1)\n",
    "dropout1 = Dropout(0.5)(conv2)\n",
    "max_pool1 = MaxPooling1D(2)(dropout1)\n",
    "cnn_output = TimeDistributed(Flatten())(max_pool1)\n",
    "\n",
    "# Bidirectional LSTM layers\n",
    "lstm1 = Bidirectional(LSTM(128, return_sequences=True))(cnn_output)\n",
    "lstm2 = Bidirectional(LSTM(128))(lstm1)\n",
    "\n",
    "# Dense layers\n",
    "dense1 = Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(lstm2)\n",
    "dropout2 = Dropout(0.5)(dense1)\n",
    "output_layer = Dense(8, activation='softmax')(dropout2)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.Precision(name=\"Precision\")])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "]\n",
    "\n",
    "model.fit(train_data.seqs, train_data.labels, batch_size=32, epochs=10, validation_split=0.1, callbacks=callbacks)\n",
    "\n",
    "# Model prediction\n",
    "model_pred = model.predict(test_data.seqs)\n",
    "y_pred = np.argmax(model_pred, axis=1)\n",
    "y_true = np.argmax(test_data.labels, axis=1)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=test_data.names, output_dict=True)\n",
    "pd.DataFrame(report).T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTSM OTIMIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 3339, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 3337, 128)    1664        ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3337, 128)   512         ['conv1d_10[0][0]']              \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 3335, 128)    49280       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 3335, 128)   512         ['conv1d_11[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 3335, 128)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 1667, 128)   0           ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 3339, 4)]    0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 426)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten_6 (Flatten)            (None, 213376)       0           ['max_pooling1d_4[0][0]']        \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)                  (None, 128)          68096       ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 128)          54656       ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 213632)       0           ['flatten_6[0][0]',              \n",
      "                                                                  'lstm_6[0][0]',                 \n",
      "                                                                  'dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          54690048    ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 256)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 8)            2056        ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 54,866,824\n",
      "Trainable params: 54,866,312\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n",
      "Epoch 1/10\n",
      "42/66 [==================>...........] - ETA: 1:48 - loss: 13.7209 - Precision: 0.4922"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import (BatchNormalization, Concatenate, Conv1D, Dense, Dropout, Flatten,\n",
    "                                    Input, LSTM, MaxPooling1D)\n",
    "from tensorflow.keras.models import Model\n",
    "import seqdata\n",
    "from transformers import AutoTokenizer, BertTokenizer, TFAutoModel\n",
    "\n",
    "# Functional Model Keras\n",
    "\n",
    "# cnn input\n",
    "cnn_input = Input(shape=(max_len, 4))\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, activation='relu')(cnn_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "cnn_out = Flatten()(x)\n",
    "\n",
    "# lstm layer\n",
    "lstm_input = Input(shape=(max_len, 4))\n",
    "lstm_out = LSTM(128)(lstm_input)\n",
    "\n",
    "# feature extraction input\n",
    "feat_extraction_input = Input(shape=(426,))\n",
    "feat_extraction_out = Dense(128, activation='relu')(feat_extraction_input)\n",
    "\n",
    "concat = Concatenate()([cnn_out, lstm_out, feat_extraction_out])\n",
    "\n",
    "dense = Dense(256, activation='relu')(concat)\n",
    "dense = Dropout(0.5)(dense)\n",
    "\n",
    "main_output = Dense(8, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[cnn_input, lstm_input, feat_extraction_input], outputs=main_output)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.Precision(name=\"Precision\")])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file='model.png',\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=False\n",
    ")\n",
    "\n",
    "model.fit([train.seqs, train.seqs, train.features], train.labels, batch_size=32, epochs=10, validation_split=0.1)\n",
    "\n",
    "model_pred = model.predict([test.seqs, test.seqs, test.features])\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for row in model_pred:\n",
    "    pred = [0 for i in range(8)]\n",
    "    pred[np.argmax(row)] = 1\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "pd.DataFrame(classification_report(test.labels, y_pred, target_names=test.names, output_dict=True)).T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs 1D e BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3339, 4)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 3337, 128)         1664      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3335, 128)         49280     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3335, 128)         0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1667, 128)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 1667, 128)        0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 1667, 256)        263168    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 256)              394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 742,280\n",
      "Trainable params: 742,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 858s 13s/step - loss: 1.9428 - Precision: 0.4545 - val_loss: 3.0756 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 878s 13s/step - loss: 1.7761 - Precision: 0.3981 - val_loss: 1.9428 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 866s 13s/step - loss: 1.6190 - Precision: 0.5568 - val_loss: 2.7909 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 1356s 21s/step - loss: 1.4554 - Precision: 0.6538 - val_loss: 2.2954 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 920s 14s/step - loss: 1.3515 - Precision: 0.6627 - val_loss: 2.1362 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 959s 14s/step - loss: 1.2858 - Precision: 0.7194 - val_loss: 2.2956 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 942s 14s/step - loss: 1.1353 - Precision: 0.7573 - val_loss: 1.8627 - val_Precision: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 903s 14s/step - loss: 1.0434 - Precision: 0.7882 - val_loss: 0.8977 - val_Precision: 0.9681 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 937s 14s/step - loss: 0.8154 - Precision: 0.8120 - val_loss: 1.2187 - val_Precision: 0.9316 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 927s 14s/step - loss: 0.7207 - Precision: 0.8287 - val_loss: 0.7942 - val_Precision: 0.9371 - lr: 0.0010\n",
      "21/21 [==============================] - 41s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miRNA</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.348624</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mRNA</th>\n",
       "      <td>0.854369</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre_miRNA</th>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.728814</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rRNA</th>\n",
       "      <td>0.972727</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snoRNA</th>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>snRNA</th>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmRNA</th>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.897059</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tRNA</th>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro avg</th>\n",
       "      <td>0.786604</td>\n",
       "      <td>0.786604</td>\n",
       "      <td>0.786604</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.695499</td>\n",
       "      <td>0.683239</td>\n",
       "      <td>0.678895</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.803847</td>\n",
       "      <td>0.786604</td>\n",
       "      <td>0.788298</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samples avg</th>\n",
       "      <td>0.786604</td>\n",
       "      <td>0.786604</td>\n",
       "      <td>0.786604</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score  support\n",
       "miRNA          0.333333  0.365385  0.348624     52.0\n",
       "mRNA           0.854369  0.946237  0.897959    186.0\n",
       "pre_miRNA      0.632353  0.860000  0.728814     50.0\n",
       "rRNA           0.972727  0.775362  0.862903    138.0\n",
       "snoRNA         0.456522  0.600000  0.518519     35.0\n",
       "snRNA          0.454545  0.227273  0.303030     22.0\n",
       "tmRNA          0.924242  0.871429  0.897059     70.0\n",
       "tRNA           0.935897  0.820225  0.874251     89.0\n",
       "micro avg      0.786604  0.786604  0.786604    642.0\n",
       "macro avg      0.695499  0.683239  0.678895    642.0\n",
       "weighted avg   0.803847  0.786604  0.788298    642.0\n",
       "samples avg    0.786604  0.786604  0.786604    642.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import (Concatenate, Conv1D, Dense, Dropout, Flatten,\n",
    "                                    Input, Bidirectional, LSTM, MaxPooling1D, TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import seqdata\n",
    "\n",
    "train = seqdata.Seq('train/')\n",
    "test = seqdata.Seq('test/')\n",
    "\n",
    "max_len = seqdata.pad_data(train, test)\n",
    "\n",
    "#train.feature_extraction([1, 2, 3, 4, 5, 6, 7, 8], True)\n",
    "#test.feature_extraction([1, 2, 3, 4, 5, 6, 7, 8], False)\n",
    "# cnn input\n",
    "cnn_input = Input(shape=(max_len, 4))\n",
    "\n",
    "x = Conv1D(filters=128, kernel_size=3, activation='relu')(cnn_input)\n",
    "x = Conv1D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPooling1D(pool_size=2)(x)\n",
    "cnn_out = TimeDistributed(Flatten())(x)\n",
    "\n",
    "# bidirectional lstm layers\n",
    "lstm_out1 = Bidirectional(LSTM(128, return_sequences=True))(cnn_out)\n",
    "lstm_out2 = Bidirectional(LSTM(128))(lstm_out1)\n",
    "\n",
    "dense = Dense(128, activation='relu', kernel_regularizer=l1_l2(l1=1e-5, l2=1e-4))(lstm_out2)\n",
    "dense = Dropout(0.5)(dense)\n",
    "\n",
    "main_output = Dense(8, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=cnn_input, outputs=main_output)\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=[tf.keras.metrics.Precision(name=\"Precision\")])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "\n",
    "model.fit(train.seqs, train.labels, batch_size=32, epochs=10, validation_split=0.1, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "model_pred = model.predict(test.seqs)\n",
    "\n",
    "y_pred = []\n",
    "\n",
    "for row in model_pred:\n",
    "    pred = [0 for i in range(8)]\n",
    "    pred[np.argmax(row)] = 1\n",
    "    y_pred.append(pred)\n",
    "\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "pd.DataFrame(classification_report(test.labels, y_pred, target_names=test.names, output_dict=True)).T\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
